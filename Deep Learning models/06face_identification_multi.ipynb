{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f0QLLUCx-Mv7"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5VgBRJej427e"
   },
   "outputs": [],
   "source": [
    "!pip install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LPbdfo2B427k"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "import cv2\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uXjK64Ss427o"
   },
   "outputs": [],
   "source": [
    "folder_path = '/content/drive/My Drive/week10/face_detection'\n",
    "detector = MTCNN()\n",
    "feature_extractor = load_model(os.path.join(folder_path, 'facenet.h5'))\n",
    "model_age = load_model(os.path.join(folder_path, 'age100.h5'))\n",
    "model_gender = load_model(os.path.join(folder_path, 'gender100.h5'))\n",
    "model_emotion = load_model(os.path.join(folder_path, 'emotion48.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iMpyxgBX427s"
   },
   "outputs": [],
   "source": [
    "# read db\n",
    "with open(os.path.join(folder_path, 'db.pickle'), 'rb') as file:\n",
    "    db = pickle.load(file)\n",
    "embeddings = db['embeddings']\n",
    "names = db['names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JKh7cZvD427v"
   },
   "outputs": [],
   "source": [
    "# detect face\n",
    "def detect_faces(img):\n",
    "    face_imgs = []\n",
    "    results = detector.detect_faces(img)\n",
    "    # extract the bounding box from the first face\n",
    "    print('# of faces: ', len(results))\n",
    "    for i in range(len(results)):\n",
    "        x1, y1, width, height = results[i]['box']\n",
    "        x2, y2 = x1 + width, y1 + height\n",
    "        patch = img[y1:y2, x1:x2] # crop face\n",
    "        face_imgs.append(patch)\n",
    "    return face_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kDHDN_sx427x"
   },
   "outputs": [],
   "source": [
    "# Standardization\n",
    "def preprocess(imgs): \n",
    "    for i in range(imgs.shape[0]):\n",
    "        # standardization\n",
    "        img = imgs[i]\n",
    "        mean, std = img.mean(), img.std()\n",
    "        img = (img - mean) / std\n",
    "        imgs[i] = img\n",
    "    return imgs\n",
    "# Normalization\n",
    "def normalize(img):\n",
    "    return img / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YUbSe1l0427z"
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(x, y):\n",
    "    sum_square = np.sum(np.square(x - y), keepdims=True)\n",
    "    return np.sqrt(sum_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GJ7iYh9R4271"
   },
   "outputs": [],
   "source": [
    "def predict_age(img):\n",
    "    img_size = 100\n",
    "    img = normalize(img)\n",
    "    img = cv2.resize(img, (img_size, img_size))\n",
    "    model_input = np.zeros((1, img_size, img_size, 3))\n",
    "    model_input[0] = img\n",
    "    ages = model_age.predict(model_input)\n",
    "    print('age: ', ages[0])\n",
    "    return \n",
    "    \n",
    "def predict_emotion(img):\n",
    "    img_size = 48\n",
    "    cls_map = ['Angry', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral', 'Disgust']\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    img = normalize(img)\n",
    "    img = cv2.resize(img, (img_size, img_size))\n",
    "    model_input = np.zeros((1, img_size, img_size, 1))\n",
    "    model_input[0] = np.expand_dims(img, axis=-1) # 48,48 -> 48,48,1\n",
    "    emotions_pred = model_emotion.predict(model_input)\n",
    "    emotion_pred = emotions_pred[0]\n",
    "    emotion_name = cls_map[np.argmax(emotion_pred)]\n",
    "    print('emotion: ', emotion_name)\n",
    "    return\n",
    "def predict_gender(img):\n",
    "    img_size = 100\n",
    "    img = normalize(img)\n",
    "    img = cv2.resize(img, (img_size, img_size))\n",
    "    model_input = np.zeros((1, img_size, img_size, 3))\n",
    "    model_input[0] = img\n",
    "    genders = model_gender.predict(model_input)\n",
    "    gender = genders[0]\n",
    "    if gender > 0.5:\n",
    "        print('Male')\n",
    "    else:\n",
    "        print('Female')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h8ovXLcl4274"
   },
   "outputs": [],
   "source": [
    "def face_id(filename, IMG_SIZE=160):\n",
    "    raw_img = cv2.imread(os.path.join(folder_path, filename))[:,:,::-1]\n",
    "    faces = detect_faces(raw_img)\n",
    "    if len(faces) == 0:\n",
    "        print('No face')\n",
    "        return\n",
    "    else:\n",
    "        # get face embeddings\n",
    "        face = faces[0]\n",
    "        # More predictions\n",
    "        predict_age(face)\n",
    "        predict_emotion(face)\n",
    "        predict_gender(face)\n",
    "        # ID\n",
    "        face = cv2.resize(face, (IMG_SIZE, IMG_SIZE))\n",
    "        model_input = np.zeros((1, IMG_SIZE, IMG_SIZE, 3))\n",
    "        model_input[0] = face\n",
    "        model_input = preprocess(model_input)\n",
    "        query_embeddings = feature_extractor.predict(model_input)\n",
    "        query_embedding = query_embeddings[0]\n",
    "        \n",
    "        # compute distance\n",
    "        distances = np.zeros((len(embeddings)))\n",
    "        for i, embed in enumerate(embeddings):\n",
    "            distance = euclidean_distance(embed, query_embedding)\n",
    "            distances[i] = distance\n",
    "\n",
    "        # find min distance    \n",
    "        idx_min = np.argmin(distances)\n",
    "        distance, name = distances[idx_min], names[idx_min]\n",
    "        print('name: ', name, ' distance: ',distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CCTM8GDk4276"
   },
   "outputs": [],
   "source": [
    "path = 'face1.jpg'\n",
    "face_id(path)\n",
    "plt.imshow(cv2.imread(os.path.join(folder_path, path))[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2gsZJamP4278"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "face_identification_multi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
